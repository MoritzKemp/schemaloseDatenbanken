\section{Hadoop}
\cite{Wartal2012}
\cite{Endlich2011}
\subsection{Einleitung}
Hadoop ist ein Java basiertes Open Source Framework von Apache. 
Die Entwicklung von Hadoop wurde als Teilpojekt von Nutch angefangen, welcher eine Weiterentwicklung von Apache Lucene darstellte. Das Ziel des Projektes Nutch war eine schnelle Websuche, also eine Alternative zu Google. Die Herausforderung für die Nutch Entwickler war es, ein System zu schaffen, welches mit hoch skalierbaren Prozessen, Redundanzen, automatischen Fehlerbeseitigung und Verteilen der Last umgehen kann. Als Google im Jahr 2004 MapReduce und \ac{GFS} Konzept vorgestellt hat, erkannte Doug Cutting, der Erfinder von Nutch, ihre Vorteile und hat sie für Nutch  übernommen. Im Jahr 2006 wurde Doug Cutting von Yahoo angeheuert das verteilte Dateisystem und das MapReduce-Framework aus dem Nutch zu extrahieren und in eigenes Framework zu überführen. So entstand Hadoop, dessen Name von dem Spielelefanten des Doug Cuttings Sohn stammt. Im Juli 2008 gewinnt Hadoop den Terabyte-Sort-Benchmark. \cite[S. 24]{Wartal2012}
Mit den neuen Konzepten von Google ermöglicht Hadoop das Verteilen der Verarbeitung komplexen Prozesse über mehrere Knoten innerhalb eines Clusters. Der größte Vorteil von Hadoop ist die Möglichkeit die  Verarbeitung der Daten zu Skalieren. Dies kann in der Umgebung von einem bis zu tausenden Knoten umgesetzt werden.
Die Hauptziele von Hadoop sind:
\begin{itemize}
\item Erreichbarkeit: Hadoop läuft in einem großen Cluster von Rechnern oder in einer Cloud wie Computed Cloud von Amazon
\item Robustheit: Wenn ein DataNode ausfehlt, übernehmen andere Knoten die Verarbeitung der Daten
\item Skalierbarkeit: Hadoop skaliert linear. Man kann einfach weitere Rechner dazu schalten um die Performance des Systems zu verbessern.
\item Einfachheit: Hadoop ermöglicht eine schnelle Entwicklung der parallelen Prozesse.
\cite{HadoopInAction}
\end{itemize}
Hadoop besteht aus mehreren Modulen, die im Weiteren kurz beschrieben werden.
\begin{itemize}
\item Hadoop Common: Es ist ein Java Modul, das von den anderen Hadoop Modulen verwendet wird. Hadoop Common stellt die Grundfunktionen bereit, die alle anderen Komponenten benötigen. Dazu zählen eine implementierungsneutrale Filesystem-Schnittstelle, die Schnittstelle für die "Remote Procedure Call"-Kommunikation im Cluster und Bibliotheken für die Serialisierung von Daten.
\item Hadoop YARN: Ein Modul für Job Scheduling und Cluster Resource Maagement
\item Hadoop Distributed File System (HDFS™): Verteiltes Dateisystem, welches einen hoch perfomanten Zugriff auf die Daten bereitstellt.
\item Hadoop MapReduce: Es ist ein auf YARN- basiertes System für die parallelen Verarbeitung der riesigen Datenmenge.
\end{itemize}
\subsection{Architektur Übersicht}
Es ist möglich Hadoop mit mehreren Dateisystemen zu betreiben: FS, HFTP FS, S3 FS usw. Das gängigste Dateisystem ist aber \ac{HDFS} (Hadoop Distributed File System). Dieses Dateisystem basiert auf dem Google File System (\ac{GFS}). 
HDFS verwendet eine Master / Slave Architektur. Dabei verwaltet der Masterknoten (NameNode) die Metadaten von dem Dateisystem. Die Slave Knoten (DataNode) speichert die aktuellen Daten.
\subsection{NameNode}
Namenode verwaltet alle Dateioperationen im Hadoop. Es beinhaltet die Information wie die Daten in die Blocks unterteilt sind, welche Knoten diese Blöcke speichern.
Die Funktionalität des NameNodes ist sehr Speicher- und I/O-lastig. Deswegen sollten diese Knoten keine Benutzerdaten speichern oder in den Berechnungsprozess angebunden sein. Daraus resultiert, dass ein Rechner nicht gleichzeitig NameNode und DataNode sein sollte.
Zusammengefasst sind die Hauptaufgabe der NameNode im Hadoop Dateisystem:
\begin{itemize}
\item Speicherung von Metadaten des Dateisystems im Hauptspeicher
\item Koordinierte Verteilung der einzelnen Datenblöcke
\item Überwachung der einzelnen Rechner-Knoten , um einen Ausfall schnell erkennen zu können 
\end{itemize}
\cite[S. XX]{Wartal2012}
Alle Daten werden in Blöcke je 64 MB aufgeteilt. Im Vergleich zu den normalen Dateisystemen ist es eine sehr großzügige Aufteilung. Zum Beispiel unterteilt das Linux Dateisystem alle Daten in 1KB große Blöcke. Die Aufteilung in solche große Blöcke bei Hadoop basiert auf der Notwendigkeit sehr große Mengen an Informationen zu verarbeiten. Um einen Datenblock zu verarbeiten benötig der NameNode in der Regel 150Byte Arbeitsspeicher. Demnach kann 1GB großer Arbeitsspeicher mehr als 6 Mio Dateien und Ordner verwalten. \cite[S. XX]{Wartal2012}
\subsection{DataNode}
\begin{itemize}
\item DataNode ist für die Speicherung der Daten in HDFS verantwortlich.
\item DataNode ist auch als Slave-Knoten bekannt.
\item DataNode berichtet dem NameNode über den Status der Datenverarbeitung in regelmäßigen Abständen. 
\item Beim Starten, meldet sich der DataNode beim NameNode an.
\item Mehrere DataNode replizieren die gleichen Daten, was die Ausfallsicherheit gewährleistet.
\item DataNode benötigt sehr viel Speicherkapazität, weil alle Daten auf dem DataNode gespeichert sind.
\end{itemize}
\cite{nameNode}
\subsection{Secondary NameNode}
Um die Aufgabe eines Secondary Nodes zu verstehen betrachten wir ganz kurz welche Dateien von einem NameNode geschrieben werden und welche Probleme dabei entstehen:
\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{images/namenode.png}
	\caption{NameNode}
	\label{img:grafik-nameNode}
\end{figure}

Wie aus der Abbildung zu sehen ist, schreibt ein NameNode zwei unterschiedliche Dateien auf die Festplatte. \\
\begin{itemize}
\item FsImage ist eine Momentane Aufnahme des Dateisystem zum Zeitpunkt des Starts des NameNodes
\item Edit Logs beinhaltet eine Menge der Änderungen, die nach dem Starten eines NameNodes auftreten.
\end{itemize}
Ein FsImage wird nur beim Neustart eines NameNodes geschrieben. Dabei wird die Information aus dem EditLog in den FsLog geschrieben um die momentane Aufnahme des Dateisystems zu speichern.\\
Da in der Regel ein NameNode sehr selten neu gestartet wird, entstehen folgende Probleme:
\begin{itemize}
\item EditLog wird sehr groß und kann nicht verwaltet werden.
\item Das Neustarten eines NameNode dauert auf Grund der großen Datenmenge sehr lange.
\item Im Fall eines Ausfalls des NameNodes geht sehr große Menge an Information verloren.
\end{itemize}
Secondary NameNode wird dafür benötigt um die oben beschriebenen Probleme zu umgehen.\\
\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{images/secondarynamenode.png}
	\caption{SecondaryNameNode}
	\label{img:grafik-SecondaryNameNode}
\end{figure}
Aufgaben eines Secondary NameNodes sind:
\begin{itemize}
\item Ein Secondary NameNode holt in der regelmäßigen Abständen die Daten aus dem EditLog und verschiebt sie in den FsImage.
\item Sobald ein neuer FsImage vorhanden ist, wird es auf den NameNode geschrieben.
\item 3. Der neue FsImage wird beim nächsten Neustart des NameNodes verwendet, was die Zeit des Prozess stark reduziert.
\end{itemize}
\cite{secNameNode}

\subsection{Replikation der Daten in Hadoop}
Hadoop verwendet einen blockorientierten Ansatz für die Datenreplikation. Mit dem Ansatz wird jede im HDFS abgelegte Datei in einzelne Blöcke mit einer festen Bytegröße aufgeteilt und durch den NameNode auf unterschiedliche Clusterknoten abgelegt. Zusätzlich wird durch den NameNode sichergestellt, dass jeder Block mehrfach auf unterschiedliche Knoten im Cluster repliziert wird.
In der HDFS-Standardkonfiguration repliziert der NameNode jeden Block dreifach. Kommt es nun zum Ausfall eines Knotens im Cluster, gehen nur die auf dem ausgefallenen Rechners sich befindlichen Blöcke verloren und keine ganze Datei, da die verloren gegangenen Blöcke durch ihre Kopien auf anderen Knoten ersetzbar sind und so der NameNode die ganze Datei bereitstellen kann.
\cite{replikation}

\subsection{Installation und Konfiguration von Hadoop}
Da Hadoop in Java implementiert ist, ist es Platformunabhängig und kann sowohl auf Windows, Linux oder MacOs installiert werden.
Im Folgenden Kapitel wird beschrieben, wie man Hadoop auf mehreren Knotten installieren kann. 

Bevor man mit der Installation des Hadoop System begint, müssen zwei Voraussetzungen erfüllt werden.
1. Die Grundlage für eine lauffähige Hadoop Instanz ist eine Java Laufzeitumgebung. Für Hadoop braucht man mind. Java Version 1.6.
Nachdem Java auf der dafür vorgesehenen Maschine installiert ist, muss man die JAVA\_HOME auf das richtige Java Verzeichnis setzen.\\
2. SSH muss installiert werden und sshd muss laufen, damit die Hadoop Scripte ausgeführt werden können.\\
Nachdem die Voraussetzungen erfüllt sind, kann man mit der Installation von Hadoop beginen. Diese beinhaltet das Laden einer Hadoop Distribution aus dem Internet und die Konfiguration dieser für ein Single- bzw ein MultipleMode. Bei einer Cluster Installation muss Hadoop auf jeden Knoten des Clusters abgelegt werden.
Man kann Hadoop auf der Seite von Apache Hadoop  (http://hadoop.apache.org/releases.html) laden.\\
Die Konfiguration von Hadoop wird auf zwei Arten von Dateien verteilt:
\begin{itemize}
\item Read-only default configuration - core-default.xml, hdfs-default.xml, yarn-default.xml and mapred-default.xml.
\item Site-specific configuration - etc/hadoop/core-site.xml, etc/hadoop/hdfs-site.xml, etc/hadoop/yarn-site.xml and etc/hadoop/mapred-site.xml.
\end{itemize}
\cite{hadoopConfiguration}


Sämtliche Konfigurationsdateien befinden sich in der Hadoop Version 2.7.3 im folgenden Verzeichnis: etc/hadoop/
Als erstes betrachten wir die Konfigurationdatei hadoop-env. In dieser Datei findet man einen Hinweis auf die installierte Java Version, spezifischen Speichereinstellugen usw. 
Eine weitere wichtige Konfigurationsdatei core-site.xml beinhaltet das Verzeichnis und die Adresse des Hadoop-Dateisystems. Bei der frischen Hadoop Installation ist diese Datei leer und muss mit Inhalt befüllt werden.
Der Parameter hadoop.tmp.dir legt fest, in welchem Verzeichnis Hadoop die benötigten Dateien für das HDFS anlegen darf.

Der Parameter fs.defaultFS beschreibt die URI von dem NameNode

Eine weitere Konfigurationsdatei hdfs-site.xml bestimmt unter anderem den Grad der Replikation innerhalb der HDFS an.
Darüber hinaus kann man in dieser Datei den Pfad zum Verzeichnis finden, in dem die Daten von dem NameNode (dfs.namenode.name.dir) oder aber die Daten von dem DataNode(dfs.datanode.data.dir) liegen.

Nach der nun allgemeinen Beschreibung der Konfiguration folgt nun die spezifische Konfiguration für das NoSQL-Cluster, dass für
dieses Projekt an der Hochschule Bonn-Rhein-Sieg den Studenten zur Verfügung gestellt wurde.

Die allgemeine Konfigurationsdatei von Hadoop, \texttt{core-site.xml}, sieht wie folgt aus:
\lstset{basicstyle=\small}
\lstinputlisting{sourcecode/core-site.xml}

\begin{description}
	\item[fs.defaultFS] Legt fest, dass das HDFS-Dateisystem auf dem \textit{c017-master}-Knoten auf Port $8026$ zugänglich ist.
	Dies ist der Anfragepunkt für alle Clients, unter anderem auch für Hbase.
	\item[topology.script.file] Beschreibt eine Routine, mit der Racks innerhalb des Clusters identifiziert werden. HDFS kann mit diesen
	Informationen die Replikation derart anpassen, dass sich zusammengehörige Daten auf dem selben Rack befinden. Im bereitgestelltem
	NoSQL-Cluster befinden sich sämltiche Nodes am selben Switch, sodass die Routine immer die gleiche ID zurück gibt
	und somit dem HDFS mitteilt. dass eine flache Cluster-Topologie mit einem einzigen Rack vorherrscht.
\end{description}

Nun folgt die Konfiguration für das HDFS-Dateisystem:
\lstset{basicstyle=\small}
\lstinputlisting{sourcecode/hdfs-site.xml}

\begin{description}
	\item[dfs.namenode.name.dir] Der Speicherort, wo das HDFS-Dateisystem seine Daten des Namenodes ablegen soll, befindet sich unter
	\texttt{/data/team6/namenode}.
	\item[dfs.namenode.http-address] Zur Überwachung des Dateisystems kann HDFS einen Webserver starten. Die Adresse ist 
	\texttt{10.20.110.61:50071}.
	\item[dfs.datanode.address] Die Adresse, auf dem der Datanode im Cluster für den Namenode erreichbar ist.
	\item[dfs.datanode.http.address] Auch für den Datanode kann HDFS einen Webserver zur Überwachung öffnen. Die Adresse ist
	\texttt{10.20.110.x:50076}, wobei \textit{x} für den jeweiligen Node (43, 39, 41, 48) steht.
	\item[dfs.datanode.ipc.address] Port für das schnelle IPC-Protokoll, mit dem die Metadaten des Dateisystems ausgetauscht werden.
	Auf allen Nodes immer auf dem Port 50026.
\end{description}

Nachdem nun HDFS fertig konfiguriert ist, folgt jetzt die Konfiguration von YARN.
\lstset{basicstyle=\small}
\lstinputlisting{sourcecode/yarn-site.xml}

\begin{description}
	\item[yarn.resourcemanager.hostname] Die Adresse jenes Nodes, auf dem der \textit{ResourceManager} laufen soll.
	Dies sollte im optimalen Fall keiner der Datanodes vom HDFS sein, damit bei voller Auslastung keine Engpässe hinsichtlich
	des Hauptspeichers und der Netzwerkanbindung entstehen. Im NoSQL-Cluster ist dies der Master-Node.
	\item[yarn.resourcemanager.address] Nochmalige Angabe des Master-Nodes mit dem Port 8036, über den der
	ResourceManager für die NodeManager erreichbar ist.
	\item[yarn.resourcemanager.scheduler.address] Die Addresse, über der der Scheduler-Service von YARN erreichbar ist.
	\item[yarn.resourcemanager.webapp.address] YARN bietet eine Weboberfläche zur Überwachung von Jobs an, die über \texttt{10.20.110.61:8086} 
	erreichbar ist.
	\item[yarn.resourcemanager.admin.address] Die Adresse des Admin-Interfaces von dem ResourceManager, über dessen Port Befehle abgesetzt werden können.
	\item[yarn.resourcemanager.zk-address] YARN kann, um eine höhere Verfügbarkeit zu gewährleisten, ZooKeeper verwenden. Hier müssen wir also die Adresse unserer
	ZooKeeper-Instanz angeben.
	\item[yarn.nodemanager.address] Die Adresse, über die die Nodemanager von Node1 bis Node4 erreichbar sind. Das ist bei jedem Node der Port \texttt{8056}
	\item[yarn.nodemanager.localizer.address] Wenn einzelne Jobs in YARN entfernte Ressourcen bzw. Datei benötigen, kann YARN diese automatisch lokal Speichern,
	damit ein schnellerer Zugriff stattfinden kann. Dieser \textit{Localizer} arbeitet mittels IPC über die hier angegebene Adresse.
	\item[yarn.nodemanager.aux-services] Angabe von zusätzlichen Hilfs-Klassen, die dann im Hadoop-Framework verwendet werden können. Hier nur die Angabe des \texttt{mapreduce\_shuffle}-Dienstes, der aber sowieso schon Standardmäßig angegeben ist.
	\item[yarn.nodemanager.aux-services.mapreduce\_shuffle.class] Die Angabe der konkrete Java-Klasse für den \texttt{mapreduce\_shuffle}-Dienst.
\end{description}

Die vollständige Liste aller Konfigurationsparameter inklusive ihrer Default-Werte finden sich unter:

\begin{itemize}
	\item \url{https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/core-default.xml}
	\item \url{http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml}
	\item \url{https://hadoop.apache.org/docs/r2.7.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml}
\end{itemize}
