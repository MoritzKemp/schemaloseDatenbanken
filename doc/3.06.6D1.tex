\section{Hadoop}
%\cite{Wartal2012}
%\cite{Endlich2011}
\subsection{Visitenkarte}%alles ohne Technologie
Hadoop ist ein Java basiertes Open Source Framework von Apache. 
Die Entwicklung von Hadoop wurde als Teilpojekt von Nutch angefangen. Nutch selber ist eine Weiterentwicklung von Apache Lucene. Das Ziel des Projektes Nutch war es eine schnelle Websuche, also eine Alternative zu Google, zu entwickeln. Die Herausforderung für die Nutch Entwickler war hierbei die Erstellung eines Systems, welches mit hoch skalierbaren Prozessen, Redundanzen, automatischer Fehlerbeseitigung und Lastverteilung umgehen kann. Als Google im Jahr 2004 MapReduce und das \ac{GFS} Konzept vorgestellt hat, erkannte Doug Cutting, der Erfinder von Nutch, die Vorteile und hat sie für Nutch übernommen. Im Jahr 2006 wurde Doug Cutting von Yahoo, seinem damaligen Arbeitgeber, damit beauftragt das verteilte Dateisystem und das MapReduce-Framework aus dem Nutch-Kontext zu extrahieren und in ein eigenes Framework zu überführen. So entstand Hadoop, dessen Name von dem Spielelefanten von Doug Cuttings Sohn stammt. Im Juli 2008 gewann Hadoop den Terabyte-Sort-Benchmark, was bereits damals die Reife des entstandenen Projektes zeigte. \cite[S. 24]{Wartal2012}

Mit den neuen Konzepten von Google ermöglicht Hadoop das Verteilen der Verarbeitung komplexer Prozesse über mehrere Knoten innerhalb eines Clusters.
Die Hauptziele von Hadoop sind:

\begin{itemize}
\item Erreichbarkeit: Hadoop läuft in einem großen Cluster von Rechnern oder in einer Cloud 
\item Robustheit: Wenn ein Knoten ausfällt, übernehmen andere Knoten die Verarbeitung der Daten
\item Skalierbarkeit: Hadoop skaliert linear. Es können dynamosch weitere Rechner dazugeschaltet werden, um damit die Performance des Systems zu verbessern.
\item Einfachheit: Hadoop ermöglicht eine schnelle Entwicklung der parallelen Prozesse. %Wirklich ??
\cite{HadoopInAction}
\end{itemize}


\subsection{Systemtechnologie}% ausgewählte technologische Aspekte (Architektur, Funktionsweise, ...) ohne (ausführliche) Modellierungsaspekte
Hadoop besteht aus mehreren Modulen, die im Weiteren kurz beschrieben werden:

\begin{figure}[htbp] 
  \centering
     \includegraphics[width=0.5\textwidth]{images/06hadoop_modules.png}
  \caption{Hadoop-Module \cite{HaMo}}
  \label{fig: Hadoop-Module}
\end{figure}

\begin{itemize}
\item Hadoop Common: Hadoop Common stellt die Grundfunktionen bereit, die alle anderen Komponenten benötigen. Dazu zählen eine implementierungsneutrale Filesystem-Schnittstelle, die Schnittstelle für die "Remote Procedure Call"-Kommunikation im Cluster und Bibliotheken für die Serialisierung von Daten.
\item Hadoop YARN: Ein Modul für das Job-Scheduling und Cluster-Resource-Maagement
\item \ac{HDFS}: Verteiltes Dateisystem, welches einen hoch perfomanten Zugriff auf die Daten bereitstellt.
\item Hadoop MapReduce: Es ist ein auf YARN- basiertes System für die parallele Verarbeitung von riesigen Datenmenge.
\end{itemize}
Es ist möglich, Hadoop mit mehreren Dateisystemen zu betreiben: FS, HFTP FS, S3 FS etc. Das gängigste Dateisystem ist aber das \ac{HDFS}. Dieses Dateisystem basiert auf dem Google File System (\ac{GFS}). 
HDFS verwendet eine Master / Slave Architektur. Dabei verwaltet der Masterknoten (NameNode) die Metadaten von dem Dateisystem. Die Slave Knoten (DataNode) speichert die aktuellen Daten.
\subsubsection{NameNode}
Der \textit{NameNode} verwaltet alle Dateioperationen im Hadoop-Cluster. Er beinhaltet Information über die Unterteilung der Daten in Blocks und auf welcehn Knoten die Blöcke gespeichert werden.
Die Prozesse des  \textit{NameNodes} sind sehr Speicher- und I/O-lastig. Deswegen sollten \textit{NameNodes} keine Benutzerdaten speichern oder in den Berechnungsprozess eingebunden sein. Daraus resultiert, dass ein Rechner nicht gleichzeitig NameNode und DataNode sein sollte.
Zusammengefasst sind die Hauptaufgaben des NameNodes im Hadoop Dateisystem:
\begin{itemize}
\item Speicherung von Metadaten des Dateisystems im Hauptspeicher
\item Koordinierte Verteilung der einzelnen Datenblöcke
\item Überwachung der einzelnen Rechner-Knoten , um einen Ausfall schnell erkennen zu können \cite[S. XX]{Wartal2012}
\end{itemize}

Alle Daten werden in Blöcke je 64 MB aufgeteilt. Im Vergleich zu gängigen Dateisystemen ist dies eine sehr großzügige Aufteilung. Zum Beispiel unterteilt das Linux Dateisystem alle Daten in 1KB große Blöcke. Die Aufteilung in solche großen Blöcke bei Hadoop basiert auf der Notwendigkeit sehr große Mengen an Informationen zu verarbeiten. Um einen Datenblock zu verarbeiten benötigt ein \textit{NameNode} in der Regel 150Byte Arbeitsspeicher. Demnach kann ein 1GB großer Arbeitsspeicher mehr als 6 Mio Dateien und Ordner verwalten. \cite[S. XX]{Wartal2012}
\subsubsection{DataNode}
Ein \textit{DataNode}, auch Slve-Knoten genannt, ist für die Speicherung der Daten in \ac{HDFS} verantwortlich. Er berichtet dem \textit{NameNode} über den Status der Datenverarbeitung in regelmäßigen Abständen und meldet sich bei seinem Start bei ihm an. Die Daten werden auf mehrere \textit{DataNodes} repliziert, um die Ausfallsicherheit gewährleisten zu können.
Ein\textit{DataNode} benötigt sehr viel Speicherkapazität, weil alle Daten ihm gespeichert sind \cite{nameNode}.


\subsubsection{Secondary NameNode}
Um die Aufgabe eines Secondary Nodes zu verstehen betrachten wir ganz kurz welche Dateien von einem NameNode geschrieben werden und welche Probleme dabei entstehen:
\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{images/namenode.png}
	\caption{NameNode}
	\label{img:grafik-nameNode}
\end{figure}

Wie aus der Abbildung zu sehen ist, schreibt ein NameNode zwei unterschiedliche Dateien auf die Festplatte. \\
\begin{itemize}
\item FsImage ist eine Momentane Aufnahme des Dateisystem zum Zeitpunkt des Starts des NameNodes
\item Edit Logs beinhaltet eine Menge der Änderungen, die nach dem Starten eines NameNodes auftreten.
\end{itemize}
Ein FsImage wird nur beim Neustart eines NameNodes geschrieben. Dabei wird die Information aus dem EditLog in den FsLog geschrieben um die momentane Aufnahme des Dateisystems zu speichern.\\
Da in der Regel ein NameNode sehr selten neu gestartet wird, entstehen folgende Probleme:
\begin{itemize}
\item EditLog wird sehr groß und kann nicht verwaltet werden.
\item Das Neustarten eines NameNode dauert auf Grund der großen Datenmenge sehr lange.
\item Im Fall eines Ausfalls des NameNodes geht sehr große Menge an Information verloren.
\end{itemize}
Secondary NameNode wird dafür benötigt um die oben beschriebenen Probleme zu umgehen.\\
\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{images/secondarynamenode.png}
	\caption{SecondaryNameNode}
	\label{img:grafik-SecondaryNameNode}
\end{figure}
Aufgaben eines Secondary NameNodes sind:
\begin{itemize}
\item Ein Secondary NameNode holt in der regelmäßigen Abständen die Daten aus dem EditLog und verschiebt sie in den FsImage.
\item Sobald ein neuer FsImage vorhanden ist, wird es auf den NameNode geschrieben.
\item 3. Der neue FsImage wird beim nächsten Neustart des NameNodes verwendet, was die Zeit des Prozess stark reduziert.
\end{itemize}
\cite{secNameNode}

\subsubsection{Replikation der Daten in Hadoop}
Hadoop verwendet einen blockorientierten Ansatz für die Datenreplikation. Mit dem Ansatz wird jede im HDFS abgelegte Datei in einzelne Blöcke mit einer festen Bytegröße aufgeteilt und durch den NameNode auf unterschiedliche Clusterknoten abgelegt. Zusätzlich wird durch den NameNode sichergestellt, dass jeder Block mehrfach auf unterschiedliche Knoten im Cluster repliziert wird.
In der HDFS-Standardkonfiguration repliziert der NameNode jeden Block dreifach. Kommt es nun zum Ausfall eines Knotens im Cluster, gehen nur die auf dem ausgefallenen Rechners sich befindlichen Blöcke verloren und keine ganze Datei, da die verloren gegangenen Blöcke durch ihre Kopien auf anderen Knoten ersetzbar sind und so der NameNode die ganze Datei bereitstellen kann.
\cite{replikation}

\subsection{Datenmodell}
In diesem Projekt wird im Bezug auf Datenmodellierung lediglich das \ac{HDFS} aus dem Hadoop-Framework genutzt. 

\subsection{Systeminstallation} % Installation auf der Grundlage unseres Clusters
Da Hadoop in Java implementiert ist, ist es Platformunabhängig und kann sowohl auf Windows, Linux oder MacOs installiert werden.
Im Folgenden Kapitel wird beschrieben, wie man Hadoop auf mehreren Knotten installieren kann. 

Bevor man mit der Installation des Hadoop System begint, müssen zwei Voraussetzungen erfüllt werden.
1. Die Grundlage für eine lauffähige Hadoop Instanz ist eine Java Laufzeitumgebung. Für Hadoop braucht man mind. Java Version 1.6.
Nachdem Java auf der dafür vorgesehenen Maschine installiert ist, muss man die JAVA\_HOME auf das richtige Java Verzeichnis setzen.\\
2. SSH muss installiert werden und sshd muss laufen, damit die Hadoop Scripte ausgeführt werden können.\\
Nachdem die Voraussetzungen erfüllt sind, kann man mit der Installation von Hadoop beginen. Diese beinhaltet das Laden einer Hadoop Distribution aus dem Internet und die Konfiguration dieser für ein Single- bzw ein MultipleMode. Bei einer Cluster Installation muss Hadoop auf jeden Knoten des Clusters abgelegt werden.
Man kann Hadoop auf der Seite von Apache Hadoop  (http://hadoop.apache.org/releases.html) laden.\\
Die Konfiguration von Hadoop wird auf zwei Arten von Dateien verteilt:
\begin{itemize}
\item Read-only default configuration - core-default.xml, hdfs-default.xml, yarn-default.xml and mapred-default.xml.
\item Site-specific configuration - etc/hadoop/core-site.xml, etc/hadoop/hdfs-site.xml, etc/hadoop/yarn-site.xml and etc/hadoop/mapred-site.xml.
\end{itemize}
\cite{hadoopConfiguration}


Sämtliche Konfigurationsdateien befinden sich in der Hadoop Version 2.7.3 im folgenden Verzeichnis: etc/hadoop/
Als erstes betrachten wir die Konfigurationdatei hadoop-env. In dieser Datei findet man einen Hinweis auf die installierte Java Version, spezifischen Speichereinstellugen usw. 
Eine weitere wichtige Konfigurationsdatei core-site.xml beinhaltet das Verzeichnis und die Adresse des Hadoop-Dateisystems. Bei der frischen Hadoop Installation ist diese Datei leer und muss mit Inhalt befüllt werden.
Der Parameter hadoop.tmp.dir legt fest, in welchem Verzeichnis Hadoop die benötigten Dateien für das HDFS anlegen darf.

Der Parameter fs.defaultFS beschreibt die URI von dem NameNode

Eine weitere Konfigurationsdatei hdfs-site.xml bestimmt unter anderem den Grad der Replikation innerhalb der HDFS an.
Darüber hinaus kann man in dieser Datei den Pfad zum Verzeichnis finden, in dem die Daten von dem NameNode (dfs.namenode.name.dir) oder aber die Daten von dem DataNode(dfs.datanode.data.dir) liegen.

Die vollständige Liste aller Konfigurationsparameter inklusive ihrer Default-Werte finden sich unter:

\begin{itemize}
	\item \url{https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/core-default.xml}
	\item \url{http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml}
	\item \url{https://hadoop.apache.org/docs/r2.7.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml}
\end{itemize}

\subsection{Datenschema}
Das logische Datenschema wird in Abschnitt \ref{hbase_datenschema}  beschrieben.

\subsection{Ad-Hoc-Zugriffsmöglichkeiten}
CRUD-Operationen können in Hadoop auch ohne HBase über einen Hive-Client durchgeführt werden. Dies war jedoch nicht Bestandteil dieses Projekts. CRUD-Operationen mit HBase werden in Abschnitt \ref{hbase_adhoc} beschrieben.
