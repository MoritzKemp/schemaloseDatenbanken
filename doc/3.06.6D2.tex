\section{HBase}

Im Folgenden wird HBase als \textbf{die} Hadoop Datenbank vorgestellt, die zu Grunde liegende Systemtechnologie erläutert  und die Installation/Konfiguration beschrieben.
\subsection{Visitenkarte}
\subsubsection{Entstehung}
Nachdem Google immer größer werdende Datenmassen speichern musste und dieses Problem mit dem  \ac{GFS} gelöst zu sein schien, stellten sich weitere Probleme heraus: 
Die Indexierung dieser Daten und die Verteilung der Daten auf viele Knoten ohne Zugriffgeschwindigkeit und Konsistenz zu verlieren. Google fand eine Lösung mit BigTable und auf Grundlage des veröffentlichten Whitepapers \cite{bigtable} dazu, entwickelte die Open-Source-Community HBase. Aus diesem Grund weisen diese beiden Datenbanken auch Gemeinsamkeiten bezüglich ihrer Funktionalität auf. Beispielsweise unterstützen beide die Komprimierung (siehe \ref{tableoperation}) und Versionierung der Daten \cite{SpaOd16}.

\subsubsection{Allgemein}
HBase wurde entwickelt, um mit Hadoop zusammen zu arbeiten, ist ein verteiltes BigData-Speichersystem 
 und bietet einen schnellen (nahe Echtzeit) Zugriff auf riesige Datenmengen.


\subsubsection{Portfolio}
HBase wird von vielen bekannten Konzernen eingesetzt, da es sich gut für Logging- und Suchsysteme eignet und als Grundpfeiler für \ac{OLAP}-Systeme geeignet ist \cite{Redt01}.

\begin{figure}[H] 
  \centering
     \includegraphics[width=0.7\textwidth]{images/{06.portfolio}.png}
  \caption{HBase-Portfolio \cite{youportf}}
  \label{fig:Portfolio}
\end{figure}

%------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\subsection{Systemtechnologie} % ausgewählte technologische Aspekte (Architektur, Funktionsweise, ...) ohne (ausführliche) Modellierungsaspekte
 In HBase lassen sich riesige Datenmengen auf mehreren Knoten verteilen, verwalten und jederzeit erweitern. HBase basiert auf Java, ist Open-Source, nicht-relational, spaltenorientiert und setzt auf ein verteiltes Dateisystem wie \ac{HDFS} von Hadoop auf \cite{hbasetut}. HBase, als Key-Value-Store, wurde als fehlertolerantes System entworfen, das auch gut mit unvollständige Datenmengen umgehen kann. Aufgrund des schemalosen Datenmodells, müssen nicht alle Felder belegt werden und verbrauchen auch keinen Speicherplatz \cite{compWo}.  Durch das \ac{WAL} und eine verteilte Konfiguration kann sich HBase schnell von Serverausfällen erholen \cite{Redt01}. 
 
 Nach CAP-Theorem legt es besonders Wert auf Verfügbarkeit und Partitionierung und vernachlässigt die Konsistenz der Daten. 
 Des Weiteren unterstützt HBase die Replikation von Hadoop, den MapReduce-Algorithmus, automatische Verteilung der Tabellen auf die Knoten, Komprimierung der Daten und Bloom-Filter. HBase kann im Standalone-Modus, im pseudo-verteilten Modus und im vollständig-verteilten Modus betrieben werden. Für den vorliegenden Use case wird am Ende des Kapitels die Konfiguration für den vollständig-verteilten Modus beschrieben. Für diesen Modus wird für die verteilte Konfiguration ein Zookeeper benötigt (siehe Abschnitt \ref{zook}). HBase stellt zwar selbst keine SQL-API zur Verfügung lässt sich aber durch Schnittstellen wie Apache Phoenix um eben solche erweitern.

\subsubsection{HBase im Vergleich zu einem \ac{RDBMS}}
HBase erinnert an eine relationale Datenbank, da die Daten in Tabellen gespeichert werden, die Zellen enthalten. Jedoch verhalten sich die Tabellen nicht wie Relationen und die Zeilen nicht wie Datensätze in relationalen Datenbanken. Auch sind die Spalten nicht durch ein Schema definiert.
HBase speichert die teils unvollständigen Daten in Spalten ab im Vergleich zu vollständigen Reiheneinträgen in einem \ac{RDBMS}. Dies ist notwendig da große Datenmengen den Anforderungen auf Vollständigkeit, wie sie ein \ac{RDBMS} erfordert, oftmals nicht gerecht werden.  
Während in einem \ac{RDBMS} viele schmale, normalisierte Tabellen vorliegen, ist HBase für Tabellen mit Millionen von nicht-normalisierten Spalten ausgelegt. Die Partitionierung wird bei HBase automatisch vorgenommen, währenddessen in einem RDBMS dies manuell erfolgen muss \cite{youintr}. Durch die Spaltenorientierung ist
HBase besonders gut für analytische Aufgaben geeignet, da es selektiv nur die benötigten Daten abfragt und nicht die komplette Zeile, wie es ein \ac{RDBMS} tut.


\subsubsection{HBase im Vergleich zu HDFS}
Da HBase selbst seine Daten nicht speichern kann, bedient es sich der \ac{HDFS}-Funktionen (siehe Abschnitt \ref{hadooptech}). Im Unterschied zu normalen Dateisystemen wie ext4 oder NTFS kümmert  sich \ac{HDFS} automatisch um die Replikation von Daten zwischen den Knoten,  
sodass eine hohe Skalierbarkeit und eine hohe Ausfallsicherheit entsteht. Da HDFS ein Filesystem ist, fehlt ihm die zufällige Lese-und Schreibfähigkeit. Eine mögliche Lösung dafür ist HBase. Es stellt innerhalb des Clusters in Echtzeit Lese- und Schreibzugriff zu den Daten her. Zur Speicherung großer Binärdaten ist die direkte Nutzung von HDFS besser geeignet \cite{compWo}. 
Es wird empfohlen HBase in einem verteilten System ab fünf Knoten einzusetzen \cite{SpaOd16}.

\begin{figure}[H] 
  \centering
     \includegraphics[width=0.7\textwidth]{images/{06.architecture}.png}
  \caption{HBase-Architektur \cite{clo11}}
  \label{fig:architecture}
\end{figure}


\subsubsection{MasterServer}
HBase besitzt zwei Rollen: den HBase \textit{MasterServer} und die \textit{RegionServer}. Der \textit{MasterServer} ist verantwortlich für die Zuweisung der Regionen (siehe Abschnitt \ref{region}) an die \textit{RegionServer}, die Verteilung der Last (Abschnitt \ref{tableoperation}), den Neustart der \textit{RegionServer}, die Teilung (Abschnitt \ref{tableoperation}) und die Überwachung der \textit{RegionServer}. Es ist möglich mehrere \textit{MasterServer} in einem Cluster zu betreiben, wobei aber nur einer aktiv sein kann. Da der \textit{MasterServer} nur verwaltende Funktionen inne hält, kann ein Cluster auch ohne ihn arbeiten, solange kein \textit{RegionServer} ausfällt. Spätestens dann muss ein \textit{MasterServer} eingreifen und die Regionen neu zuweisen. Die Verfügbarkeit des \textit{MasterServers} wird vom Zookeeper verwaltet \cite{Redt01}.

\subsubsection{RegionServer}
Der \textit{RegionServer} beinhaltet die HBase Regionen (siehe \ref{region}) und die HBase-Daten, welche lexikographisch nach dem Reihenschlüssel sortiert  werden. Die Aufrufe der JAVA-API gehen direkt an die \textit{RegionServer}, damit der \textit{MasterServer} nicht als Flaschenhals agiert. Der \textit{RegionServer} komprimiert und verteilt die Daten und berichtet dem  \textit{MasterServer}. Es wird empfohlen nur einen \textit{RegionServer} pro Maschine zu betreiben \cite{Redt01}. Für Lese-und Schreibzugriffe kommuniziert der \textit{RegionServer} mit anderen \textit{RegionServern}.

\begin{figure}[H] 
  \centering
     \includegraphics[width=0.9\textwidth]{images/{06.cluster}.png}
  \caption{Exemplarische Aufteilung der Tabelle in Regionen}
  \label{fig:cluster}
\end{figure}


%------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\subsection{Datenmodell} %Modellierungsaspekte

\subsubsection{Tabellen}\label{tabelle}
HBase speichert die Daten, ähnlich wie eine relationale Datenbank in Tabellen. Jedoch bestehen diese aus Reihenschlüsseln und Spaltenfamilien (siehe \ref{sf}). Es gibt zwei Arten von Tabellen: Die Benutzer-Tabellen und die System-Tabellen.
Die Systemtabellen werden für das Verwalten von Meta-Daten von \acp{ACL}, Tabellen, Regionen (siehe \ref{region}) und Namensräumen verwendet. Die Benutzer-Tabellen werden im vorliegenden Projekt für die Verwaltung des Million-Song-Dataset verwendet. Folgend ein Beispiel einer solchen Tabelle:

\begin{figure}[htbp] 
  \centering
     \includegraphics[width=0.7\textwidth]{images/{06.logisch}.pdf}
  \caption{Logische Darstellung der Daten}
  \label{fig:Logische Darstellung der Daten}
\end{figure}


\subsubsection{Regionen}\label{region}
Eine Tabelle besteht aus Spalten und Reihen. Für die Skalierung  und den randomisierten Zugriff, teilt HBase die Tabelle horizontal in Regionen auf, d.h. jede Region besteht aus einer Reihe von aufeinander folgenden Schlüsseln. Jede Region wird genau einem \textit{RegionServer} zugeordnet, um Konsistenz zu wahren. Der HBase Load-Balancer sorgt dafür, dass die Regionen auf alle \textit{RegionServer} gleich verteilt werden. Jede Region wird durch einen Start-Schlüssel und einen End-Schlüssel begrenzt. Diese Informationen lassen sich in den System-Tabellen wiederfinden. Regionen können geteilt werden, wenn sie zu groß werden oder zusammengelegt werden, wenn die zu klein sind.

\subsubsection{Spaltenfamilien}\label{sf}
Die Empfehlung ist, dass Daten mit gleichen Zugriffs-Queries und demselben Format in einer Spaltenfamilie zusammengefasst werden sollten. Wenn wir beispielsweise zu allen Songs des One-Million-Song-Datasets die Coverbilder der Songs hinterlegt hätten, könnten die Bilder in einer Spaltenfamilie und die textuellen Informationen zu den Songs in einer anderen Spaltenfamilie hinterlegt werden. So könnte die Spaltenfamilie mit den textuellen Informationen komprimiert werden (siehe Abschnitt \ref{tableoperation}). Wenn bestimmte Daten nur gelesen werden und andere meistens geschrieben werden, sollte ebenfalls über eine separate Spaltenfamilie nachgedacht werden. Es gibt keine Grenze nach oben für die Spaltenfamilien innerhalb einer Tabelle, jedoch leidet die Performanz bei vielen Spaltenfamilien. Der \textit{MemStore} (siehe \ref{memstore} wird dadurch belastet und generiert viele kleine Dateien. Bei der Tabellenerzeugung  muss bis auf die Spaltenfamilien keine feste Vorgabe gemacht werden. Alles außer der Tabellenname wird als Byte-Array abgespeichert, d.h. man kann Zeichen, Zahlen, Buchstaben usw. abspeichern. Um auf einen Wert zugreifen zu können, muss der Reihenschlüssel, die Spaltenfamilie, der Spaltenname und  Zeitstempel (optional) angegeben werden \cite{SpaOd16}. In der folgenden Abbildung ist zu sehen, wie HBase seine Daten abspeichert:

\begin{figure}[H] 
  \centering
     \includegraphics[width=0.9\textwidth]{images/{06.physisch}.pdf}
  \caption{Physische Darstellung einer Tabelle}
  \label{fig:Physische Darstellung einer Tabelle}
\end{figure}

\subsubsection{Spalten}
Spalten werden nicht durch eine Schema-Beschreibung vorgegeben und können jederzeit zu einer Spaltenfamilie hinzugefügt werden. Jede Spalte kann mehrere Versionen (Abschnitt \ref{versionen}) erhalten. 

\subsubsection{Stores}
Es gibt einen Store pro Spaltenfamilie. Ein Store gruppiert den \textit{MemStore} und \textbf{0-n} \textit{Store}-Files (HFiles). 

\subsubsection{MemStore}\label{memstore}
Wenn Daten hinzugefügt oder geändert werden, wird ein \ac{WAL} erzeugt und in den \textit{MemStore} geschrieben, wo der Eintrag lexikographisch einsortiert wird. Ist der Im-Memory Speicher des \textit{MemStore} voll, werden die Daten als HFile im \ac{HDFS} abgespeichert. Die Logdateien im \textit{MemStore} werden erst gelöscht, wenn alle Änderungen festgeschrieben wurden. So wird sichergestellt, dass die Daten nicht verloren gehen, falls ein Knoten abstürzt.

\subsubsection{HFiles}
HFiles (Key-Value-Map) werden erzeugt, wenn die \textit{MemStores} voll sind und werden im HDFS abgespeichert, um von der Hadoop-Persistierung und Replikation zu profitieren. HFiles bestehen aus Blöcken. Ein Block hat eine Größe zwischen 8KB und 1 MB. Die Blockgröße kann konfiguriert werden.  Die Standard-Größe liegt bei 64KB. Es gibt viele Blocktypen die innerhalb eines HFiles vorkommen können: Der Datenblock enthält sowohl die Daten als auch die \textit{Put- und Delete-Markierungen}. Indexblocks ermöglichen das schnelle Auffinden einer Reihe innerhalb eines HFiles. Bloom-Filter-Blocks werden für das Überspringen von  bestimmten Parse-Vorgängen genutzt, damit der angefragte Schlüssel schneller gefunden werden kann. Trailer Blocks enthalten die HFile-Version. 
%HFiles sind unveränderlich, da HDFS kein Update erlaubt.
Zusammenfassende eine Darstellung der HBase-Architektur:

\begin{figure}[H] 
  \centering
     \includegraphics[width=1\textwidth]{images/{06.regionserverinternals}.png}
  \caption{RegionServer-Interna \cite{carmc}}
  \label{fig:Internals}
\end{figure}

\subsubsection{Interne Tabellenoperationen }\label{tableoperation}
Die große Stärke von HBase ist es, Daten zu größeren Dateien zusammenzufassen und Tabellen automatisch auf mehrere Rechner zu verteilen. Hierzu verwendet HBase drei verschiedene Mechanismen.
\begin{description}
\item[Komprimierung]
 Um zu vermeiden, dass beim \textit{Memstore-Flush} (siehe \ref{memstore}) viele kleine HFiles entstehen, legt HBase sie zu größeren Dateien zusammen.  Alle Dateien mit dem gleichen Schlüssel, aber einem älteren Zeitstempel werden so gelöscht. Beim Löschen von Zellen setzt HBase einen Marker, der bei der Komprimierung überprüft wird. In einer weiteren Stufe der Komprimierung können alle Marker gelöscht werden. Eine solche Komprimierung kann manuell für eine spezifische Region oder Tabelle angestoßen werden. Außerdem werden standardmäßig wöchentlich solche Komprimierungen von HBase selbst ausgeführt \cite{SpaOd16}.

\item[Teilung]
Das Gegenteil der Komprimierung ist die Teilung (Split), auch \textit{Auto-Sharding} genannt. Wenn eine Region eine Größe von 10GB erreicht, führt HBase eine Teilung durch und es entstehen zwei neue Regionen. Hierbei ist zu beachten, dass Teilungen immer spaltenfamilienübergreifend stattfinden \cite{SpaOd16}:

\begin{figure}[H] 
  \centering
     \includegraphics[width=0.7\textwidth]{images/{06.split}.pdf}
  \caption{Zwei Spaltenfamilien vor und nach der Teilung}
  \label{fig:Teilung}
\end{figure}


\item[Verteilung der Last]
Eine Verteilung der Last ist insbesondere bei der Neuordnung von Daten (Komprimierung) oder der Veränderung der Cluster-Umgebung (neuer oder gelöschter Rechnerknoten) notwendig.
HBase, um genau zu sein Hadoop, führt alle fünf Minuten einen LoadBalancer aus der algorithmisch sicherstellt, dass alle \textit{RegionServer} eine ähnliche Anzahl an Regionen bedienen \cite{SpaOd16}. 
\end{description}

 \subsubsection{Versionierung}\label{versionen}
Eine Reihe, eine Spalte und ein Zeitstempel spezifizieren exakt eine Zelle in HBase. Während Spalten und Reihen gleich bleiben können, ändert sich der Zeitstempel für jede Zelle. Der Zeitstempel, als Long-Integer-Datentyp, wird in absteigender Reihenfolge hinterlegt, sodass immer der aktuellste Wert aus den HFiles gelesen wird \cite{reference}.
Standardmäßig können drei Versionen einer Zelle erstellt werden.


\subsubsection{Zugriff auf HBase}
Obwohl aus Performanzgründen empfohlen wird die JAVA-API für den Zugriff auf HBase zu nutzen, werden im Folgenden weitere Möglichkeiten vorgestellt.
\begin{description}
\item[Thrift Server]
Der Thrift Server kann als Gateway benutzt werden, um Applikationen  anderer Sprachen, den Zugriff auf HBase zu ermöglichen. Ein C/C++ Client könnte bei dieser Lösung jedoch nur mit dem Thrift Server kommunizieren und nicht direkt auf einen \textit{RegionServer} zugreifen.

\item[REST Server]
HBase stellt auch eine REST-API zur Verfügung, auf die über HTTP zugegriffen werden kann.

\item[Hive] Mit Hilfe von SQL-Queries ist ein Zugriff auf HBase möglich, jedoch auf Kosten der Performanz (4-5mal langsamer) \cite{clo11}.
\end{description}

%------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\subsection{Systeminstallation} %Installation auf der Grundlage unseres Clusters 
Für die Installation werden sowohl auf dem  \textit{MasterServer} als auch auf den \textit{RegionServern} folgende UNIX-Kommandos abgesetzt:
\noindent 
\begin{lstlisting}[language=bash]
  $ wget http://www-us.apache.org/dist/hbase/stable/
    hbase-1.2.4-bin.tar.gz
  $ tar -xzf hbase-1.2.4-bin.tar.gz
  $ ln -s hbase-1.2.4 hbase
  $ cd hbase
  $ export PATH=$PATH:~/hbase/bin
\end{lstlisting}

Die Konfiguration für HBase wird in einer Datei namens \textit{hbase-site.xml} erstellt. Hier werden Zookeeper-Einstellungen vorgenommen, das HDFS-System referenziert und der Betriebsmodus sowie der Pfad zur Datenspeicherung eingestellt.
Um HBase zu starten, wird der Befehl 
\noindent 
\begin{lstlisting}[language=bash]
  $ {HBASE_HOME}/bin/start-hbase.sh 
\end{lstlisting}
ausgeführt. HBase lässt sich mit dem Standard-Port 16010 durch folgenden \ac{URL} über die Weboberfläche aufrufen: \textit{localhost:16010}

\subsubsection{ZooKeeper}\label{zook}
ZooKeeper ist ein Open-Source-Projekt unter der Apache-Foundation. Typische Aufgabenstellungen sind:
\begin{itemize}
\item Wettlaufsituationen beim verteilten Schreiben auf denselben Daten zu lösen
\item Den Zugriff auf schon veraltete Daten zu regeln 
\item Das Auffinden von Rechnerknoten (\textit{RegionServern}) in einem Cluster
\item Überwachung der einzelnen Knoten im Cluster durch sogenannte \textit{Heartbeats}. Dies sind kurze Signale an den  \textit{MasterServer}, die signalisieren, dass der Rechnerknoten noch aktiv ist. 
\end{itemize}

Die Installation von ZooKeeper ist verhältnismäßig einfach. Nachdem die Anwendung auf die einzelnen Knoten herunter geladen ist, muss in der Datei \url{zookeeper/conf/zoo.cfg}
die Konfiguration erfolgen, die im einfachsten Falle nur aus der Angabe der Rechner-Knoten besteht. Innerhalb von ZooKeeper nennt sich so ein Verbund
von Rechner-Knoten ein \textit{esemble}. Diese Konfiguration muss anschließend auf alle Knoten verteilt werden. Danach kann der ZooKeeper-Server, genannt \texttt{zkServer},
auf jedem Knoten manuell gestartet werden. 

Über den Client-Port von ZooKeeper, der in diesem Projekt auf jedem Knoten der Port $2186$ ist, können die verteilten
Anwendungen die ZooKeeper-API verwenden. Dabei können sie sogenannte \textit{zNodes} anlegen. Das sind Dateien, auf die verteilt zugegriffen wird und um dessen
Gültigkeit sich nun ZooKeeper kümmert, sodass die verteilte Anwendung sich nicht mehr um die typischen Probleme, die in einem Cluster auftauchen, kümmern muss.

%------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\subsection{Datenschema}\label{hbase_datenschema}
Für das Semesterprojekt wurde eine Tabelle mit dem Namen \textbf{music} angelegt. Diese enthält zwei Spaltenfamilien. Die Spaltenfamilie \textbf{song} enthält die für die Use cases (siehe Abschnitt \ref{usecases}) benötigten Daten und die Spaltenfamilie
\textbf{miscellaneous} enthält die restlichen Daten des Million-Song-Datasets:

\begin{figure}[H] 
  \centering
     \includegraphics[width=0.7\textwidth]{images/{06.datenschema}.pdf}
  \caption{Tabelle  \textbf{music}}
  \label{fig:datenschema}
\end{figure}



%------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
\subsection{Ad-Hoc-Zugriffsmöglichkeiten}\label{hbase_adhoc}
Um Ad-Hoc auf die Daten der Datenbank zuzugreifen, verwendet man das mitgelieferte Kommandozeilenprogramm \textbf{hbase shell}, welches in JRuby geschrieben wurde. Um das Tool aufzurufen navigiert man mittels:
\begin{lstlisting}[language=bash]
  $ cd hbase
\end{lstlisting}
in das HBase-Verzeichnis und setzt die Umgebungsvariable mit:
\begin{lstlisting}[language=bash]
  $ export PATH=$PATH:~/hbase/bin
\end{lstlisting}
Im Anschluss daran kann das Tool mit:
\begin{lstlisting}[language=bash]
  $ hbase shell
\end{lstlisting}
aufgerufen werden.

Um sich alle Tabellen anzeigen zu lassen benötigt man folgenden Befehl:
\begin{lstlisting}[language=bash]
  $ list
\end{lstlisting}
Und um zu sehen welche Server aktiv sind, verwendet man diesen Befehl:
\begin{lstlisting}[language=bash]
  $ status
\end{lstlisting}

\subsubsection{CRUD-Befehle}
\begin{description}
\item[Create] Da es keine SQL-API bei HBase gibt, wird das Einfügen von Daten durch folgendes Kommando realisiert:
\begin{lstlisting}[language=bash]
  $ put 'music', 'TestRowKey', 'song:ArtistName','Team6_Test'
\end{lstlisting}
Beim Schreiben fragt der Client den Zookeeper nach der Systemtabelle (siehe \ref{tabelle}), die die Information enthält, in welcher Region der Datensatz vorhanden ist. Dann durchsucht der Client die Region des \textit{Regionservers}, um den Schlüssel zu finden.
Nachdem der Client vom \textit{RegionServer} die Erlaubnis erhalten hat zu schreiben, wird ein Logeintrag im \ac{WAL} erzeugt.
\item[Read] Um die ganze Tabelle zu lesen würde man das Kommando \textbf{scan} verwenden, jedoch würde dies für die vorliegenden Daten unübersichtlich werden, weshalb es sich empfiehlt die Ausgabe zu limitieren:
\begin{lstlisting}[language=bash]
  $ scan 'music' ,{'LIMIT' => 5}
\end{lstlisting}
Um an einen einzelnen Datensatz zu kommen, muss man die \textit{SongId} mit angeben:
\begin{lstlisting}[language=bash]
  $ get 'music', 'TestRowKey'
\end{lstlisting}
Beim Lesen fragt der Client wie beim Schreiben den Zookeeper und durchsucht die Systemtabelle nach Meta-Daten ab, um den Schlüssel zu finden. Dann fragt der Client den \textit{RegionServer} nach dem Schlüssel-Wert-Paar und im Anschluss daran wird der \textit{MemStore}
nach dem Schlüssel durchsucht.
\item[Update] Um einen Wert zu aktualisieren, verwendet man den \textbf{Put}-Befehl und gibt den zu ersetzenden und den neuen Wert an:
\begin{lstlisting}[language=bash]
  $ put 'music', 'TestRowKey', 'song:ArtistName',
  'Team6_Test'
\end{lstlisting}
\item[Delete] Das Löschen funktioniert so wie das Einfügen, nur das die Zelle mit einer Löschmarkierung versehen wird: 
\begin{lstlisting}[language=bash]
  $ deleteall 'music', 'TestRowKey'
\end{lstlisting}
\end{description}


