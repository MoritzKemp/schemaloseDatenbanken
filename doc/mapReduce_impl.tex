\subsection{Implementierung von MapReduce-Funktionen}

Dieser Abschnitt beschreibt die Implementierung von Map-Reduce-Funktionen, die auf den Daten
des Million-Song-Datensatzes arbeiten. Vorausgesetzt wird, dass der Million-Song-Datensatz als
CSV-Datei bereit in das HDFS-Dateisystem importiert ist. Die hier vorgestellten MapReduce-Funktionen
arbeiten ausschließlich mit Daten auf dem HDFS-Dateisystem, abgesehen von den Zwischenergebnissen,
die auf dem lokalen Dateisystem des jeweiligen Knotens abgelegt werden.
Für die Implementierung wird die Java-API des MapReduce von Hadoop verwendet. Wichtig ist,
dass die aktuelle MapReduce-API verwendet wird, und nicht die inzwischen veraltete MapRed-API.
Eine gute Hilfe bei der Entwicklung von map- und reduce-Funktionen bietet \cite{miner2012mapreduce}.

\subsubsection{Entfernung von doppelten Musikeinträgen}

Die erste Implementierung der MapReduce-Funktionen überführt alle Songs aus der ursprünglichen
CSV-Datei in eine neue CSV-Datei, in der erstens kein Song mehr doppelt vorkommt und zweitens
ein Song nur noch eine Untermenge der ursprünglichen Attribute enthält. Damit soll der ursprüngliche
Datenbestand auf einen reduzierten Datenbestand mit den für den Nutzer interessanten Attributen 
transformiert werden. Die map-Funktion ist dafür verantwortlich, die Attribute eines Musikstückes
zu identifizieren und daraus mit einen neuen Musikstück-Eintrag zu erzeugen, der nur noch die interessanten
Attribute enthält.
Zuerst muss definiert werden, welche Eingabeparameter die map-Funktion bekommt. Dazu gibt es verschiedene
Eingabeformate der MapReduce-API, unter denen man wählen kann. Weil die Daten in der CSV-Datei für das
MapReduce-Framework nichts weiter als reiner Text ist, wird das \textit{Text}-Format als Eingabe für
die map-Funktion gewählt, welches gleichzeitig auch das Standard-Format für die map-Funktion ist.
Das Format des Schlüssel-Parameters wird nicht weiter angegeben, weil der Schlüsselwert in diesem Falle 
während der Verarbeitung keine Rolle spielt.

Die map-Funktion \ref{mapreduce:strippedMap} teilt den übergebenen Wert des Textes in die Song-Attribute auf, indem es den Text
als einzelnen String betrachtet und mittels der \textit{split}-Methode ein Feld von Strings erzeugt, die durch
das Komma im ursprünglichem String getrennt sind. Dadurch sind die Musik-Attribute als Strings nun einzelnen verfügbar.
Der neue Eintrag für den Song wird durch das Erzeugen eines neuen Strings und dem Anhängen ausgewählter
Attribute erzeugt. Ist der neue String fertig zusammen gebaut, wird er wieder in das hadoop-spezifische \textit{Text}
konvertiert und als Zwischenergebnis dem MapReduce-Framework übergeben. Dieses erwartet neben dem 
Wert aber auch einen Schlüssel. Der Schlüssel ist in dem Falle ebenfalls vom Typ \textit{Text}, der als Wert die
Song-ID des Musikstückes enthält.

\lstset{
    language=Java,
    basicstyle=\ttfamily,
    frame=single,
    breaklines=true,
    postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\hookrightarrow\space}}
}

\begin{lstlisting}[caption={Map-Funktion zur Entfernung von mehrfachen Musikeinträgen}, label=mapreduce:strippedMap]
int untilGenreAttr = 13;
int fromGenreAttr = 147;
int maxNumOfAttr = 166;
int songIdColumn = 6;
Text strippedSongAttr = new Text();
Text songId = new Text();

protected void map(Object key, Text value, Context context) {
  String[] allAttributes = value.toString().split(",", maxNumOfAttr);
  String newStrippedValue = new String();
  songId.set(allAttributes[songIdColumn-1]);
      
  for(int i=0; i<untilGenreAttr; i++){
    newStrippedValue += ","+allAttributes[i];
  }
      
  for(int k=fromGenreAttr-1; k<maxNumOfAttr; k++){
    newStrippedValue += ","+allAttributes[k];
  }
      
  strippedSongAttr.set(newStrippedValue);
  context.write(songId, strippedSongAttr);
}
\end{lstlisting}

Die reduce-Funktion \ref{mapreduce:strippedReduce} bekommt beim Aufruf als Eingabe eine Liste jener Zwischenergebnisse, die den gleichen 
Schlüssel-Wert haben, was in diesem Falle die Song-ID ist. 
Diese Funktion schreibt nun als Ergebnis das erste Element der Liste raus. Alle anderen
Einträge werden ignoriert. Somit erzeugt diese MapReduce-Implementierung eine neue Liste
von Musikstücken ohne Mehrfacheinträge für den gleichen Musiksong.

\begin{lstlisting}[caption={Reduce-Funktion zur Entfernung von mehrfachen Musikeinträgen}, label=mapreduce:strippedReduce]
protected void reduce(Text key, Iterable<Text> values, Context context) {
  resultValue = values.iterator().next();
  context.write(key, resultValue);
}
\end{lstlisting}


\subsubsection{Anzahl produzierter Musikstücke der Künstler}
Die nächste Map-Reduce-Implementierung ermöglicht die Ermittlung, wie viele 
Musikstücke ein bestimmter Künstler bereits geschrieben beziehungsweise herausgegeben
hat. Diese Implementierung arbeitet dabei auf den Datenstrukturen von Hbase und nicht,
wie zuvor, direkt auf dem HDFS. Dies drückt sich vor allem in der Verwendung der 
\texttt{TableMapper}- und \texttt{TableReducer}-Klassen aus, die von Hbase als spezialisierte \texttt{Mapper}- beziehungsweise \texttt{Reducer}-Klassen zur Verfügung gestellt werden.
Diese spezialisierten Klassen sind in der Lage, das Ergebnis einer Hbase-Abfrage so zu
zerteilen, dass das Map-Reduce-Framework der Map-Funktion immer eine Datenreihe 
als Eingabe übergibt. Ähnliches gilt auch für die Reduce-Funktion, dessen Ergebnis
nun nicht direkt eine Datei auf dem HDFS ist, sondern die Daten mit einem Hbase-Aufruf übergeben
werden.

Die Map-Funktion \ref{mapreduce:countArtistSongsMap} überführt die Daten einer ganzen
Datenreihe aus der Hbase-Datenbank in ein Schlüssel-Wert-Paar. Dieses enthält, ähnlich 
dem Beispiel mit dem Zählen von Wörtern, als Schlüssel den Künstlernamen und als Wert
die Zahl $1$. Damit repräsentiert das Zwischenergebnis einen Song eines bestimmten Künstlers.

\begin{lstlisting}[caption={Map-Funktion zur Anzahl der Musikstücke pro Künstler}, label=mapreduce:countArtistSongsMap]
Text artist_name = new Text();
IntWritable ONE = new IntWritable(1);
byte[] CF_SONG = "song".getBytes();
byte[] ATTR_NAME = "ArtistName".getBytes();

protected void map(ImmutableBytesWritable rowkey, Result value, Context context) {
  String val = new String(value.getValue(CF_SONG, ATTR_NAME));
  artist_name.set(val);
  context.write(artist_name, ONE);
}
\end{lstlisting}

Die Reduce-Funktion \ref{mapreduce:countArtistSongsReduce} bekommt die Liste aller
Zwischenergebnisse des gleichen Künsters und zählt die Elemente dieser Liste. Das Ergebnis
repräsentiert die Anzahl der Songs von diesem Künstler, welches als Ergebnis in eine 
Hbase-Tabelle geschrieben wird.

\begin{lstlisting}[caption={Reduce-Funktion zur Anzahl der Musikstücke pro Künstler}, label=mapreduce:countArtistSongsReduce]
byte[] CF_COMMON = "com".getBytes();
byte[] ATTR_SONGNUM = "NumOfSongs".getBytes();

protected void reduce(Text key, Iterable<IntWritable> values, Context context) {
  int i=0;
  for(IntWritable val : values){
    i += val.get();
  }          
  Put put = new Put(Bytes.toBytes(key.toString()));
  put.add(CF_COMMON, ATTR_SONGNUM, Bytes.toBytes(i));
  context.write(null, put);
}
\end{lstlisting}

\subsubsection{Anzahl der Musikstücke pro Künstler mit einem bestimmten Thema}
Diese Map-Reduce-Implementierung realisiert die Anforderung, dass die Musikstücke über
ihren Titel auf ein bestimmtes Thema hin untersucht werden. Der Titel muss dafür ein bestimmtes
Wort, dass das Thema festlegt, beinhalten. Als Ergebnis soll eine Liste von Künstlern erstellt werden,
die jeweils alle mindestens ein Musikstück produziert haben, dass das Thema enthält sowie auch
die Anzahl, wie viele Musikstücke mit dem jeweiligen Thema vorhanden sind.

Die Map-Funktion \ref{mapreduce:songsWithTopicSongsMap} filtert die Musikstücke danach, ob sie im Title ein bestimmtes Wort enthalten.
Ist dies der Fall, wir als Schlüssel-Wert-Paar der Künstlername als Schlüssel und die $1$ als 
Wert als Zwischenergebnis geschrieben. Enthält das Musikstück das gesuchte Wort nicht,
so kehrt die Funktion ohne Zwischenergebnis zurück.

\begin{lstlisting}[caption={Map-Funktion zur Suche nach Musikstücken eines Themas}, label=mapreduce:songsWithTopicSongsMap]
Text artist_name = new Text();
IntWritable ONE = new IntWritable(1);
byte[] CF_SONG = "song".getBytes();
byte[] ATTR_NAME = "ArtistName".getBytes();
byte[] ATTR_TITLE = "SongName".getBytes();
        
protected void map(ImmutableBytesWritable rowkey, Result value, Context context) {
            
  String name = new String(value.getValue(CF_SONG, ATTR_NAME));
  String title = new String(value.getValue(CF_SONG, ATTR_TITLE));          
  CharSequence topic = "love";
            
  if(!title.contains(topic)) return;
            
  artist_name.set(name);
  context.write(artist_name, ONE);
}
\end{lstlisting}

Die Reduce-Funktion zählt, wie in der vorherigen Map-Reduce-Implementierung auch, die Elemente der Liste des gleichen Künstlers.
Das Ergebnis wird ebenfalls in eine Hbase-Tabelle geschrieben und repräsentiert die Anzahl der Musikstücke, die der
Künstler zu dem bestimmten Thema geschrieben hat.

\begin{lstlisting}[caption={Reduce-Funktion zur Suche nach Musikstücken eines Themas}, label=mapreduce:songsWithTopicSongsReduce]
byte[] CF_COMMON = "com".getBytes();
byte[] ATTR_TOPIC = "love".getBytes();

protected void reduce(Text key, Iterable<IntWritable> values, Context context) {
  int i=0;
  for(IntWritable val : values){
    i += val.get();
  }
            
  Put put = new Put(Bytes.toBytes(key.toString()));
  put.add(CF_COMMON, ATTR_TOPIC, Bytes.toBytes(i));
  context.write(null, put);
}
\end{lstlisting}